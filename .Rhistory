id_name = ifelse(time == 'Pre', paste(id, 'A', sep=''), paste(id, 'B', sep=''))
file_tag = paste("\'", id_name, "_data.xlsx\'", sep = '')
return(file_tag)
}
process_accel(id = 'P1', time = 'Pre')
process_accel = function(id, time = c('Pre', 'Post')) {
id_name = ifelse(time == 'Pre', paste(id, 'A', sep=''), paste(id, 'B', sep=''))
path = paste("\'", id_name, "_data.xlsx\'", sep = '')
#Load files
summary = read_xlsx(path, sheet = 4)
daily = read_xlsx(path, sheet =3 )
}
id_name = ifelse(time == 'Pre', paste(id, 'A', sep=''), paste(id, 'B', sep=''))
process_accel = function(id, time = c('Pre', 'Post')) {
id_name = ifelse(time == 'Pre', paste(id, 'A', sep=''), paste(id, 'B', sep=''))
path = paste("\'", id_name, "_data.xlsx\'", sep = '')
#Load files
summary = read_xlsx(path, sheet = 4)
daily = read_xlsx(path, sheet =3 )
}
process_accel(id = 'P1', time = 'Pre')
setwd("~/Library/CloudStorage/Box-Box/R Analyses/2020 PCHI/Accelerometer Processing")
process_accel(id = 'P1', time = 'Pre')
process_accel(id = 'P1', time = 'Pre')
process_accel(id = 'P1', time = 'Pre')
process_accel = function(id, time = c('Pre', 'Post')) {
id_name = ifelse(time == 'Pre', paste(id, 'A', sep=''), paste(id, 'B', sep=''))
path = paste(id_name, "_data.xlsx", sep = '')
#Load files
summary = read_xlsx(path, sheet = 4)
daily = read_xlsx(path, sheet =3 )
}
process_accel(id = 'P1', time = 'Pre')
process_accel = function(id, time = c('Pre', 'Post')) {
id_name = ifelse(time == 'Pre', paste(id, 'A', sep=''), paste(id, 'B', sep=''))
path = paste(id_name, "_data.xlsx", sep = '')
#Load files
summary = read_xlsx(path, sheet = 4)
daily = read_xlsx(path, sheet =3 )
}
process_accel(id = 'P1', time = 'Pre')
P1A_summary <- supressMessages(read_xlsx("P1A_data.xlsx", sheet = 4))
message()
help(message)
P1A_summary = supressMessages(read_xlsx("P1A_data.xlsx", sheet = 4))
P1A_summary = suppressMessages(read_xlsx("P1A_data.xlsx", sheet = 4))
daily = suppressMessages(read_xlsx(path, sheet = 3)
}
process_accel = function(id, time = c('Pre', 'Post')) {
process_accel = function(id, time = c('Pre', 'Post')) {
path = paste(id_name, "_data.xlsx", sep = '')
#Load files
summary = suppressMessages(read_xlsx(path, sheet = 4))
daily = suppressMessages(read_xlsx(path, sheet = 3)
}
process_accel = function(id, time = c('Pre', 'Post')) {
)
process_accel = function(id, time = c('Pre', 'Post')) {
id_name = ifelse(time == 'Pre', paste(id, 'A', sep=''), paste(id, 'B', sep=''))
path = paste(id_name, "_data.xlsx", sep = '')
#Load files
summary = suppressMessages(read_xlsx(path, sheet = 4))
daily = suppressMessages(read_xlsx(path, sheet = 3))
}
process_accel(id = 'P1', time = 'Pre')
process_accel(id = 'P1', time = 'Pre')
process_accel = function(id, time = c('Pre', 'Post')) {
id_name = ifelse(time == 'Pre', paste(id, 'A', sep=''), paste(id, 'B', sep=''))
path = paste(id_name, "_data.xlsx", sep = '')
#Load files
summary = suppressMessages(read_xlsx(path, sheet = 4))
daily = suppressMessages(read_xlsx(path, sheet = 3))
return(summary)
return(daily)
}
process_accel(id = 'P1', time = 'Pre')
return(c(summary, daily))
process_accel = function(id, time = c('Pre', 'Post')) {
id_name = ifelse(time == 'Pre', paste(id, 'A', sep=''), paste(id, 'B', sep=''))
path = paste(id_name, "_data.xlsx", sep = '')
#Load files
summary = suppressMessages(read_xlsx(path, sheet = 4))
daily = suppressMessages(read_xlsx(path, sheet = 3))
return(c(summary, daily))
}
process_accel(id = 'P1', time = 'Pre')
process_accel = function(id, time = c('Pre', 'Post')) {
id_name = ifelse(time == 'Pre', paste(id, 'A', sep=''), paste(id, 'B', sep=''))
path = paste(id_name, "_data.xlsx", sep = '')
#Load files
summary = suppressMessages(read_xlsx(path, sheet = 4))
daily = suppressMessages(read_xlsx(path, sheet = 3))
load(c(summary, daily))
}
process_accel(id = 'P1', time = 'Pre')
process_accel = function(id, time = c('Pre', 'Post')) {
id_name = ifelse(time == 'Pre', paste(id, 'A', sep=''), paste(id, 'B', sep=''))
path = paste(id_name, "_data.xlsx", sep = '')
#Load files
summary = read_xlsx(path, sheet = 4)
daily = read_xlsx(path, sheet = 3)
load(c(summary, daily))
}
process_accel(id = 'P1', time = 'Pre')
process_accel = function(id, time = c('Pre', 'Post')) {
id_name = ifelse(time == 'Pre', paste(id, 'A', sep=''), paste(id, 'B', sep=''))
path = paste(id_name, "_data.xlsx", sep = '')
#Load files
summary = read_xlsx(path, sheet = 4)
daily = read_xlsx(path, sheet = 3)
}
process_accel(id = 'P1', time = 'Pre')
process_accel = function(id, time = c('Pre', 'Post')) {
id_name = ifelse(time == 'Pre', paste(id, 'A', sep=''), paste(id, 'B', sep=''))
path = paste(id_name, "_data.xlsx", sep = '')
#Load files
summary = read_xlsx(path, sheet = 4)
daily = read_xlsx(path, sheet = 3)
}
process_accel(id = 'P1', time = 'Pre')
process_accel(id = 'P1', time = 'Pre')
process_accel = function(id, time = c('Pre', 'Post')) {
id = id
time = time
id_name = ifelse(time == 'Pre', paste(id, 'A', sep=''), paste(id, 'B', sep=''))
path = paste(id_name, "_data.xlsx", sep = '')
#Load files
summary = read_xlsx(path, sheet = 4)
daily = read_xlsx(path, sheet = 3)
summary$MVPAbouts_days_wk = sum((as.numeric(paste(daily$`Number of Sasaki MVPA 10 min bouts occurring on this day...30`))>0), na.rm=TRUE)
as.numeric(paste(summary[1,]))
AvgNum_bouts_Sed10 = summary$`Sed 150 10 min Bouts`/summary$`Calendar Days`
AvgTime_bouts_Sed10 = summary$`Total Time in Sed 150 10 min Bouts`/summary$`Calendar Days`
AvgLength_bouts_Sed10 = summary$`Avg Time per Sed 150 10 min Bout`
AvgNum_bouts_Sed20 = summary$`Sed 150 20 min Bouts`/summary$`Calendar Days`
AvgTime_bouts_Sed20 = summary$`Total Time in Sed 150 20 min Bouts`/summary$`Calendar Days`
AvgLength_bouts_Sed20 = summary$`Avg Time per Sed 150 20 min Bout`
AvgNum_bouts_Sed30 = summary$`Sed 150 30 min Bouts`/summary$`Calendar Days`
AvgTime_bouts_Sed30 = summary$`Total Time in Sed 150 30 min Bouts`/summary$`Calendar Days`
AvgLength_bouts_Sed30 = summary$`Avg Time per Sed 150 30 min Bout`
AvgNum_bouts_Sed60 = summary$`Sed 150 60 min Bouts`/summary$`Calendar Days`
AvgTime_bouts_Sed60 = summary$`Total Time in Sed 150 60 min Bouts`/summary$`Calendar Days`
AvgLength_bouts_Sed60 = summary$`Avg Time per Sed 150 60 min Bout`
AvgNum_MVPAbouts = summary$`Sasaki MVPA 10 min Bouts`/summary$`Calendar Days`
TotTimeMVPAbouts = summary$`Total Time in Sasaki MVPA 10 min Bouts`
AvgTime_MVPAbouts = summary$`Total Time in Sasaki MVPA 10 min Bouts`/summary$`Calendar Days`
Avg_length_MVPAbouts = summary$`Avg Time per Sasaki MVPA 10 min Bout`
MVPAbouts_days_wk = summary$MVPAbouts_days_wk
Avg_SedMin = summary$Sedentary/summary$`Calendar Days`
Avg_LightMin = summary$Light/summary$`Calendar Days`
Avg_ModMin = summary$Moderate/summary$`Calendar Days`
Avg_VigMin = summary$Vigorous/summary$`Calendar Days`
PctTime_Sed = summary$`% in Sedentary`
TotMVPAmin = summary$`Total MVPA`
AvgMVPA_Min = summary$`Average MVPA per day`
Steps_per_min = summary$`Steps Per Minute`
Avg_hrs_worn = (as.numeric(paste(summary$Time))/summary$`Calendar Days`)/60
AvgSteps = summary$`Steps Counts`/summary$`Calendar Days`
Days_worn = summary$`Calendar Days`
output = data.frame(id, time, AvgNum_bouts_Sed10, AvgTime_bouts_Sed10, AvgLength_bouts_Sed10,
AvgNum_bouts_Sed20, AvgTime_bouts_Sed20, AvgLength_bouts_Sed20,
AvgNum_bouts_Sed30, AvgTime_bouts_Sed30, AvgLength_bouts_Sed30,
AvgNum_bouts_Sed60, AvgTime_bouts_Sed60, AvgLength_bouts_Sed60,
AvgNum_MVPAbouts, TotTimeMVPAbouts, AvgTime_MVPAbouts, Avg_length_MVPAbouts,
MVPAbouts_days_wk, Avg_SedMin, Avg_LightMin, Avg_ModMin, Avg_VigMin,
PctTime_Sed, TotMVPAmin, AvgMVPA_Min, AvgSteps, Steps_per_min, Avg_hrs_worn, Days_worn)
}
process_accel(id = 'P1', time = 'Pre')
return(output)
process_accel = function(id, time = c('Pre', 'Post')) {
id = id
time = time
id_name = ifelse(time == 'Pre', paste(id, 'A', sep=''), paste(id, 'B', sep=''))
path = paste(id_name, "_data.xlsx", sep = '')
#Load files
summary = read_xlsx(path, sheet = 4)
daily = read_xlsx(path, sheet = 3)
summary$MVPAbouts_days_wk = sum((as.numeric(paste(daily$`Number of Sasaki MVPA 10 min bouts occurring on this day...30`))>0), na.rm=TRUE)
as.numeric(paste(summary[1,]))
AvgNum_bouts_Sed10 = summary$`Sed 150 10 min Bouts`/summary$`Calendar Days`
AvgTime_bouts_Sed10 = summary$`Total Time in Sed 150 10 min Bouts`/summary$`Calendar Days`
AvgLength_bouts_Sed10 = summary$`Avg Time per Sed 150 10 min Bout`
AvgNum_bouts_Sed20 = summary$`Sed 150 20 min Bouts`/summary$`Calendar Days`
AvgTime_bouts_Sed20 = summary$`Total Time in Sed 150 20 min Bouts`/summary$`Calendar Days`
AvgLength_bouts_Sed20 = summary$`Avg Time per Sed 150 20 min Bout`
AvgNum_bouts_Sed30 = summary$`Sed 150 30 min Bouts`/summary$`Calendar Days`
AvgTime_bouts_Sed30 = summary$`Total Time in Sed 150 30 min Bouts`/summary$`Calendar Days`
AvgLength_bouts_Sed30 = summary$`Avg Time per Sed 150 30 min Bout`
AvgNum_bouts_Sed60 = summary$`Sed 150 60 min Bouts`/summary$`Calendar Days`
AvgTime_bouts_Sed60 = summary$`Total Time in Sed 150 60 min Bouts`/summary$`Calendar Days`
AvgLength_bouts_Sed60 = summary$`Avg Time per Sed 150 60 min Bout`
AvgNum_MVPAbouts = summary$`Sasaki MVPA 10 min Bouts`/summary$`Calendar Days`
TotTimeMVPAbouts = summary$`Total Time in Sasaki MVPA 10 min Bouts`
AvgTime_MVPAbouts = summary$`Total Time in Sasaki MVPA 10 min Bouts`/summary$`Calendar Days`
Avg_length_MVPAbouts = summary$`Avg Time per Sasaki MVPA 10 min Bout`
MVPAbouts_days_wk = summary$MVPAbouts_days_wk
Avg_SedMin = summary$Sedentary/summary$`Calendar Days`
Avg_LightMin = summary$Light/summary$`Calendar Days`
Avg_ModMin = summary$Moderate/summary$`Calendar Days`
Avg_VigMin = summary$Vigorous/summary$`Calendar Days`
PctTime_Sed = summary$`% in Sedentary`
TotMVPAmin = summary$`Total MVPA`
AvgMVPA_Min = summary$`Average MVPA per day`
Steps_per_min = summary$`Steps Per Minute`
Avg_hrs_worn = (as.numeric(paste(summary$Time))/summary$`Calendar Days`)/60
AvgSteps = summary$`Steps Counts`/summary$`Calendar Days`
Days_worn = summary$`Calendar Days`
output = data.frame(id, time, AvgNum_bouts_Sed10, AvgTime_bouts_Sed10, AvgLength_bouts_Sed10,
AvgNum_bouts_Sed20, AvgTime_bouts_Sed20, AvgLength_bouts_Sed20,
AvgNum_bouts_Sed30, AvgTime_bouts_Sed30, AvgLength_bouts_Sed30,
AvgNum_bouts_Sed60, AvgTime_bouts_Sed60, AvgLength_bouts_Sed60,
AvgNum_MVPAbouts, TotTimeMVPAbouts, AvgTime_MVPAbouts, Avg_length_MVPAbouts,
MVPAbouts_days_wk, Avg_SedMin, Avg_LightMin, Avg_ModMin, Avg_VigMin,
PctTime_Sed, TotMVPAmin, AvgMVPA_Min, AvgSteps, Steps_per_min, Avg_hrs_worn, Days_worn)
return(output)
}
process_accel(id = 'P1', time = 'Pre')
output = process_accel(id = 'P1', time = 'Pre')
View(output)
load(Process_Accelerometer_Function.R)
load('Process_Accelerometer_Function.R')
load('Process_Accelerometer_Function.R')
load('Process_Accelerometer_Function.R')
source('Process_Accelerometer_Function.R')
id.list = data.frame(Subject = c('P1', 'P2'),
time = c('Pre', 'Pre'))
finaloutput = data.frame()
for(i in 1:nrow(id.list){
for(i in 1:nrow(id.list)){
# Part I - filter
input = id.list[i, ]
# Part II - Run function to calculate multiple text similarity scores
output = process_accel(input)
#Merge
finaloutput = rbind(finaloutput, output)
}
process_accel = function(id, time = c('Pre', 'Post')) {
id = id
time = time
id_name = ifelse(time == 'Pre', paste(id, 'A', sep=''), paste(id, 'B', sep=''))
path = paste(id_name, "_data.xlsx", sep = '')
#Load files
summary = read_xlsx(path, sheet = 4)
daily = read_xlsx(path, sheet = 3)
summary$MVPAbouts_days_wk = sum((as.numeric(paste(daily$`Number of Sasaki MVPA 10 min bouts occurring on this day...30`))>0), na.rm=TRUE)
as.numeric(paste(summary[1,]))
AvgNum_bouts_Sed10 = summary$`Sed 150 10 min Bouts`/summary$`Calendar Days`
AvgTime_bouts_Sed10 = summary$`Total Time in Sed 150 10 min Bouts`/summary$`Calendar Days`
AvgLength_bouts_Sed10 = summary$`Avg Time per Sed 150 10 min Bout`
AvgNum_bouts_Sed20 = summary$`Sed 150 20 min Bouts`/summary$`Calendar Days`
AvgTime_bouts_Sed20 = summary$`Total Time in Sed 150 20 min Bouts`/summary$`Calendar Days`
AvgLength_bouts_Sed20 = summary$`Avg Time per Sed 150 20 min Bout`
AvgNum_bouts_Sed30 = summary$`Sed 150 30 min Bouts`/summary$`Calendar Days`
AvgTime_bouts_Sed30 = summary$`Total Time in Sed 150 30 min Bouts`/summary$`Calendar Days`
AvgLength_bouts_Sed30 = summary$`Avg Time per Sed 150 30 min Bout`
AvgNum_bouts_Sed60 = summary$`Sed 150 60 min Bouts`/summary$`Calendar Days`
AvgTime_bouts_Sed60 = summary$`Total Time in Sed 150 60 min Bouts`/summary$`Calendar Days`
AvgLength_bouts_Sed60 = summary$`Avg Time per Sed 150 60 min Bout`
AvgNum_MVPAbouts = summary$`Sasaki MVPA 10 min Bouts`/summary$`Calendar Days`
TotTimeMVPAbouts = summary$`Total Time in Sasaki MVPA 10 min Bouts`
AvgTime_MVPAbouts = summary$`Total Time in Sasaki MVPA 10 min Bouts`/summary$`Calendar Days`
Avg_length_MVPAbouts = summary$`Avg Time per Sasaki MVPA 10 min Bout`
MVPAbouts_days_wk = summary$MVPAbouts_days_wk
Avg_SedMin = summary$Sedentary/summary$`Calendar Days`
Avg_LightMin = summary$Light/summary$`Calendar Days`
Avg_ModMin = summary$Moderate/summary$`Calendar Days`
Avg_VigMin = summary$Vigorous/summary$`Calendar Days`
PctTime_Sed = (summary$`% in Sedentary`)*100
TotMVPAmin = summary$`Total MVPA`
AvgMVPA_Min = summary$`Average MVPA per day`
Steps_per_min = summary$`Steps Per Minute`
Avg_hrs_worn = (as.numeric(paste(summary$Time))/summary$`Calendar Days`)/60
AvgSteps = summary$`Steps Counts`/summary$`Calendar Days`
Days_worn = summary$`Calendar Days`
output = data.frame(id, time, AvgNum_bouts_Sed10, AvgTime_bouts_Sed10, AvgLength_bouts_Sed10,
AvgNum_bouts_Sed20, AvgTime_bouts_Sed20, AvgLength_bouts_Sed20,
AvgNum_bouts_Sed30, AvgTime_bouts_Sed30, AvgLength_bouts_Sed30,
AvgNum_bouts_Sed60, AvgTime_bouts_Sed60, AvgLength_bouts_Sed60,
AvgNum_MVPAbouts, TotTimeMVPAbouts, AvgTime_MVPAbouts, Avg_length_MVPAbouts,
MVPAbouts_days_wk, Avg_SedMin, Avg_LightMin, Avg_ModMin, Avg_VigMin,
PctTime_Sed, TotMVPAmin, AvgMVPA_Min, AvgSteps, Steps_per_min, Avg_hrs_worn, Days_worn)
return(output)
}
id.list = data.frame(id = c('P1', 'P2'),
time = c('Pre', 'Pre'))
finaloutput = data.frame()
for(i in 1:nrow(id.list)){
# Part I - filter
input = id.list[i, ]
# Part II - Run function to calculate multiple text similarity scores
output = process_accel(time = input$time, id = input$id)
#Merge
finaloutput = rbind(finaloutput, output)
}
View(finaloutput)
process_accel(id = 'P2', time = 'Pre')
source('Process_Accelerometer_Function.R')
id.list = data.frame(id = c('P1', 'P2'),
time = c('Pre', 'Pre'))
process_accel(id = 'P2', time = 'Pre')
source('Process_Accelerometer_Function.R')
process_accel(id = 'P2', time = 'Pre')
str_replace_all("$10", fixed("$"), "")
source('Process_Accelerometer_Function.R')
process_accel(id = 'P2', time = 'Pre')
source('Process_Accelerometer_Function.R')
process_accel(id = 'P2', time = 'Pre')
finaloutput = data.frame()
for(i in 1:nrow(id.list)){
# Part I - filter
input = id.list[i, ]
# Part II - Run function to calculate multiple text similarity scores
output = process_accel(time = input$time, id = input$id)
#Merge
finaloutput = rbind(finaloutput, output)
}
View(finaloutput)
filelist = list.files(pattern = ".*.xlsx")
filelist
filelist = list.files(pattern = ".*.xlsx")
filelist
filelist = data.frame.files(pattern = ".*.xlsx")
filelist = data.frame(list.files(pattern = ".*.xlsx"))
View(filelist)
filelist = data.frame(list.files(pattern = ".*.xlsx")) %>%
rename('path' = 1)
#Grab all Excel Files
filelist = data.frame(list.files(pattern = ".*.xlsx")) %>%
rename('path' = 1) %>%
mutate(id = str_replace_all(path, '_data.xlsx', ''))
#Grab all Excel Files
filelist = data.frame(list.files(pattern = ".*.xlsx")) %>%
rename('path' = 1) %>%
mutate(id = str_replace_all(path, '_data.xlsx', ''))
View(filelist)
#Grab all Excel Files
filelist = data.frame(list.files(pattern = ".*.xlsx")) %>%
rename('path' = 1) %>%
mutate(id = str_replace_all(path, '_data.xlsx', ''),
time = str_sub(id, start =-1))
#Grab all Excel Files
filelist = data.frame(list.files(pattern = ".*.xlsx")) %>%
rename('path' = 1) %>%
mutate(id = str_replace_all(path, '_data.xlsx', ''),
time_short = str_sub(id, start =-1),
time = ifelse(time_short == 'A', 'Pre', 'Post'))
#Grab all Excel Files
filelist = data.frame(list.files(pattern = ".*.xlsx")) %>%
rename('path' = 1) %>%
mutate(id_full = str_replace_all(path, '_data.xlsx', ''),
time_short = str_sub(id_full, start =-1),
time = ifelse(time_short == 'A', 'Pre', 'Post'),
id = str_sub(id_full, start = -2))
#Grab all Excel Files
filelist = data.frame(list.files(pattern = ".*.xlsx")) %>%
rename('path' = 1) %>%
mutate(id_full = str_replace_all(path, '_data.xlsx', ''),
time_short = str_sub(id_full, start =-1),
time = ifelse(time_short == 'A', 'Pre', 'Post'),
id = substring(id_full, 1, nchar(idfull) -1))
#Grab all Excel Files
filelist = data.frame(list.files(pattern = ".*.xlsx")) %>%
rename('path' = 1) %>%
mutate(id_full = str_replace_all(path, '_data.xlsx', ''),
time_short = str_sub(id_full, start =-1),
time = ifelse(time_short == 'A', 'Pre', 'Post'),
id = substring(id_full, 1, nchar(id_full) -1))
source('Process_Accelerometer_Function.R')
id.list = data.frame(id = c('P1', 'P2'),
time = c('Pre', 'Pre'))
process_accel(id = 'P2', time = 'Pre')
test = filelist[1,]
process_accel(id = id, time = time, path = path,  data = test)
finaloutput = data.frame()
for(i in 1:nrow(id.list)){
# Part I - filter
input = id.list[i, ]
# Part II - Run function to calculate multiple text similarity scores
output = process_accel(time = input$time, id = input$id)
#Merge
finaloutput = rbind(finaloutput, output)
}
finaloutput = data.frame()
for(i in 1:nrow(id.list)){
# Part I - filter
input = id.list[i, ]
# Part II - Run function to calculate multiple text similarity scores
output = process_accel(time = time, id = id, path = path, data = id.list)
#Merge
finaloutput = rbind(finaloutput, output)
}
View(filelist)
filelist$path[1]
#Grab all Excel Files
filelist = data.frame(list.files(pattern = ".*.xlsx")) %>%
rename('path' = 1) %>%
mutate(id_full = str_replace_all(path, '_data.xlsx', ''), # Remove path data
time_short = str_sub(id_full, start =-1), #Isolate time
time = ifelse(time_short == 'A', 'Pre', 'Post'), #Reformat Time
id = substring(id_full, 1, nchar(id_full) -1), #removes the last character from each string
path = paste('\'', path, '\''))
finaloutput = data.frame()
for(i in 1:nrow(id.list)){
# Part I - filter
input = id.list[i, ]
# Part II - Run function to calculate multiple text similarity scores
output = process_accel(time = time, id = id, path = path, data = id.list)
#Merge
finaloutput = rbind(finaloutput, output)
}
test = filelist[1,]
process_accel(id = id, time = time, path = path, data = test)
#Grab all Excel Files
filelist = data.frame(list.files(pattern = ".*.xlsx")) %>%
rename('path' = 1) %>%
mutate(id_full = str_replace_all(path, '_data.xlsx', ''), # Remove path data
time_short = str_sub(id_full, start =-1), #Isolate time
time = ifelse(time_short == 'A', 'Pre', 'Post'), #Reformat Time
id = substring(id_full, 1, nchar(id_full) -1)) #removes the last character from each string
#  path = paste('\'', path, '\''))
test = filelist[1,]
process_accel(id = id, time = time, path = path, data = test)
# Part II - Run function to calculate multiple text similarity scores
output = process_accel(time = time, id = id, path = path, data = input)
finaloutput = data.frame()
for(i in 1:nrow(id.list)){
# Part I - filter
input = id.list[i, ]
# Part II - Run function to calculate multiple text similarity scores
output = process_accel(time = time, id = id, path = path, data = input)
#Merge
finaloutput = rbind(finaloutput, output)
}
input$path
filelist$path
finaloutput = data.frame()
for(i in 1:nrow(id.list)){
# Part I - filter
input = id.list[i, ]
# Part II - Run function to calculate multiple text similarity scores
output = process_accel(time = time, id = id, path = path, data = id.list[i,])
#Merge
finaloutput = rbind(finaloutput, output)
}
test = filelist[1,]
process_accel(id = id, time = time, path = path, data = test)
test = filelist[2,]
process_accel(id = id, time = time, path = path, data = test)
# Part II - Run function to calculate multiple text similarity scores
output = process_accel(time = time, id = id, path = path, data = test[i,])
finaloutput = data.frame()
for(i in 1:nrow(test)){
# Part I - filter
input = id.list[i, ]
# Part II - Run function to calculate multiple text similarity scores
output = process_accel(time = time, id = id, path = path, data = test[i,])
#Merge
finaloutput = rbind(finaloutput, output)
}
test = filelist[1:5,]
process_accel(id = id, time = time, path = path, data = test)
finaloutput = data.frame()
for(i in 1:nrow(test)){
# Part I - filter
input = id.list[i, ]
# Part II - Run function to calculate multiple text similarity scores
output = process_accel(time = time, id = id, path = path, data = test[i,])
#Merge
finaloutput = rbind(finaloutput, output)
}
test = filelist[1:10,]
finaloutput = data.frame()
for(i in 1:nrow(test)){
# Part I - filter
input = id.list[i, ]
# Part II - Run function to calculate multiple text similarity scores
output = process_accel(time = time, id = id, path = path, data = test[i,])
#Merge
finaloutput = rbind(finaloutput, output)
}
finaloutput = data.frame()
for(i in 1:nrow(filelist)){
# Part I - filter
input = id.list[i, ]
# Part II - Run function to calculate multiple text similarity scores
output = process_accel(time = time, id = id, path = path, data = filelist[i,])
#Merge
finaloutput = rbind(finaloutput, output)
}
View(finaloutput)
source('Process_Accelerometer_Function.R')
test = filelist[1,]
process_accel(id = id, time = time, path = path, data = test)
test = filelist[1,]
process_accel(id = id, time = time, path = path, data = test)
library(tidyverse); library(readxl)
source('Process_Accelerometer_Function.R')
single_run = data.frame(id = 'P1', time = 'Pre', path = 'P1A_data.xlsx', time_short = 'A', id_full = 'P1A')
#Process File
processed = process_accel(id = id, time = time, path = path, data = single_run)
processed
setwd("~/Library/CloudStorage/Box-Box/GitHub/Accelerometer_Processing")
print(single_run$id_full, '_Accelerometer_processed.csv')
single_run$id_full
paste(single_run$id_full, '_Accelerometer_processed.csv')
paste(single_run$id_full, '_Accelerometer_processed.csv', sep = '')
output_path = paste(single_run$id_full, '_Accelerometer_processed.csv', sep = '')
output_path
write.csv(processed, out, row.names = FALSE)
write.csv(processed, output_path, row.names = FALSE)
output_path = paste(single_run$id_full, '_accelerometer_processed.csv',
sep = '')
